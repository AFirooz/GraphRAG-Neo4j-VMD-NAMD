{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8179d327",
   "metadata": {},
   "source": [
    "# <span style='color:Tomato;'>Load Env Variables</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c5816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import utils\n",
    "\n",
    "\n",
    "# Add the modules directory to the Python path if needed\n",
    "# sys.path.append(os.path.abspath(\"./modules\"))\n",
    "\n",
    "# load variables into env\n",
    "root_dir = utils.get_project_root()\n",
    "f = root_dir / \".secrets\" / \".env\"\n",
    "assert f.exists(), f\"File not found: {f}\"\n",
    "dotenv.load_dotenv(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4737d57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.runnables import  RunnablePassthrough\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from pydantic import BaseModel, Field\n",
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "# from langchain_community.graphs import Neo4jGraph\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from langchain_community.chat_models import ChatOllama\n",
    "# from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "# from neo4j import GraphDatabase\n",
    "# from yfiles_jupyter_graphs import GraphWidget\n",
    "# from langchain_community.vectorstores import Neo4jVector\n",
    "# from langchain_community.document_loaders import TextLoader\n",
    "# from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\n",
    "# from langchain_ollama import OllamaEmbeddings\n",
    "# from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61b8b91",
   "metadata": {},
   "source": [
    "# <span style='color:Tomato;'>Process PDFs</span>\n",
    "\n",
    "We'll use Langchain PyMuPDF4LLM\n",
    "\n",
    "## <span style='color:Orange;'>Initialization</span>\n",
    "\n",
    "### <span style='color:Khaki;'>Basic Imports</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74d0d9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpprint\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpickle\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Markdown, display\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import sys\n",
    "from pathlib import Path\n",
    "import pprint\n",
    "import pickle\n",
    "import tqdm\n",
    "from IPython.display import Markdown, display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755813f9",
   "metadata": {},
   "source": [
    "### <span style='color:Khaki;'>initializing the graph database</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2898792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_neo4j import Neo4jGraph\n",
    "\n",
    "graph = Neo4jGraph()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf5e7cb",
   "metadata": {},
   "source": [
    "### <span style='color:Khaki;'>Loading PDF file</span>\n",
    "\n",
    "You can either use `load()` method to do it all at once in memory or inclemently do it using `lazy_load()`.\n",
    "\n",
    "Since our docs are big, we'll use `lazy_load()` to also see the progress.\n",
    "\n",
    "To save time, we will load the docs from a pickle file if previously processed, otherwise process them and save them as a pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2053b0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/DATA/Ali_Data/GraphRAG-Neo4j-VMD-NAMD/data/pdfs/VMD_user_guid_2016.pdf\n",
      "vmd_user_guid_2016\n"
     ]
    }
   ],
   "source": [
    "# pdf file\n",
    "file_path = (Path() / \"..\" / \"data\" / \"pdfs\" / \"VMD_user_guid_2016.pdf\").resolve()\n",
    "\n",
    "file_name = file_path.stem.lower()\n",
    "\n",
    "assert file_path.exists(), f\"File not found: {file_path}\"\n",
    "\n",
    "# create directory for pkl files\n",
    "pkl_dir = file_path.parent.parent / \"pkls\"\n",
    "pkl_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(file_path)\n",
    "print(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beac619d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading docs from pdf. \n",
      "This will take some time (~5 min)\n",
      "Loaded vmd_user_guid_2016: 265 documents\n"
     ]
    }
   ],
   "source": [
    "from langchain_pymupdf4llm import PyMuPDF4LLMLoader\n",
    "\n",
    "\n",
    "loader = PyMuPDF4LLMLoader(file_path)\n",
    "\n",
    "\n",
    "if (pkl_dir / f\"docs_{file_name}.pkl\").exists():\n",
    "    print(\"Loading docs from pickle\")\n",
    "    with open(pkl_dir / f\"docs_{file_name}.pkl\", \"rb\") as f:\n",
    "        docs = pickle.load(f)\n",
    "else:\n",
    "    print(\"Loading docs from pdf. \\nThis will take some time (~5 min)\")\n",
    "\n",
    "    # Option 1: loading small docs\n",
    "    # docs = loader.load()\n",
    "\n",
    "    # Option 2: Load documents asynchronously (almost 3x faster)\n",
    "    docs = await loader.aload()\n",
    "\n",
    "    # Option 3: lazy load with progress bar\n",
    "    # todo: make this asynchronous\n",
    "    # pages = []\n",
    "    # docs = []\n",
    "    # for doc in tqdm.tqdm(loader.lazy_load()):\n",
    "    #     pages.append(doc)\n",
    "    #     # process the pages in chunks\n",
    "    #     if len(pages) >= 100:\n",
    "    #         docs.extend(pages)\n",
    "    #         pages = []\n",
    "\n",
    "    # pickle save the docs\n",
    "    with open(pkl_dir / f\"docs_{file_name}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(docs, f)\n",
    "\n",
    "print(f\"Loaded {file_name}: {len(docs)} documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac331c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
